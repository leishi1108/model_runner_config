[DEFAULT]
workspace = /home/shilei/fbpmx/list_items_classification/list_items_classification_${date}
reset = True
re_predict = True


[project]
actions = generate, train, evaluate


[evaluators]
keys = expert_predictor, expert_evaluator



[models]
keys = pretrained_trained.low_lr,pretrained_trained,base_trained


[datasets]
keys = list_item_label_train, train_candidate_position_feature, unlabeled, labeled, topk


[dataset_list_item_label_train]
class = ExistsDataset
reset = False
; copy from "/home/shilei/fbpmx/items_classification/items_classification_20231009/dataset_list_item_label_train"


[dataset_train_candidate_position_feature]
class = ReadFileDataset
format = json
dir = /home/shilei/corpus/list_items_data/list_item_label_train.json
reset = False

[dataset_train_candidate]
class = MapDataset
input = list_item_label_train
expression = exec('import uuid') or {'item_id': uuid.uuid4().hex}
keep_exists = True
reset = False


[dataset_train_candidate_position_merge]
class = MergeIntoDataset
base_dataset = train_candidate
merge_datasets = train_candidate_position_feature
merge_type = merge_replace
merge_key = _index_
merge_values = start,end
reset = False


[dataset_list_item_labeled]
class = ReadFileDataset
format = json
dir = /home/shilei/corpus/list_items_data/list_item_label_train_retrieve.json


[dataset_input]
class = MergeIntoDataset
base_dataset = train_candidate_position_merge
merge_datasets = list_item_labeled
merge_type = merge_replace
merge_key = item_id
merge_values = classify_prediction,standard_prediction


[dataset_unlabeled]
class = FilterDataset
input = input
filters = ("classify_prediction" not in x) or (("classify_prediction" in x) and (x["classify_prediction"] is None))


[dataset_labeled]
class = FilterDataset
input = input
filters = ("classify_prediction" in x) and (x["classify_prediction"] is not None)


[dataset_labeled_trans]
class = MapDataset
input = labeled
expression = {'label': x["classify_prediction"]}
keep_exists = True


[model_pretrained_trained.low_lr]
class = MultiClassificationModel
; data = labeled_trans
data = list_item_label_test_train
bert_base = /home/shilei/fbpmx/items_classification_with_context/items_classification_with_context_20231021/model_roberta_pretrained_trained.2/model
text = text
with_context=1
context=context
learning_rate = 2.0e-6
num_epochs = 70
train_ratio = 0.85
batch_size = 128
max_seq_length = 128
labels=专业,分部分项,材料,材料属性,构件,构件属性,工序,工种,费用,机械,群体,单体,配套建筑,楼层,流水段,空间,地上地下,部位构件

[model_pretrained_trained]
class = MultiClassificationModel
; data = labeled_trans
data = list_item_label_test_train
bert_base = /home/shilei/fbpmx/items_classification_with_context/items_classification_with_context_20231021/model_roberta_pretrained_trained.2/model
text = text
with_context=1
context=context
learning_rate = 2.0e-5
num_epochs = 70
train_ratio = 0.85
batch_size = 128
max_seq_length = 128
labels=专业,分部分项,材料,材料属性,构件,构件属性,工序,工种,费用,机械,群体,单体,配套建筑,楼层,流水段,空间,地上地下,部位构件

[model_base_trained]
class = MultiClassificationModel
; data = labeled_trans
data = list_item_label_test_train
bert_base = /home/shilei/model_repository/chinese-roberta-wwm-ext
text = text
with_context=1
context=context
learning_rate = 2.0e-5
num_epochs = 70
train_ratio = 0.85
batch_size = 128
max_seq_length = 128
labels=专业,分部分项,材料,材料属性,构件,构件属性,工序,工种,费用,机械,群体,单体,配套建筑,楼层,流水段,空间,地上地下,部位构件


#######################################

[dataset_list_item_label_test]
class = ReadFileDataset
format = json
dir = /home/shilei/corpus/list_items_data/list_item_label_test_retrieve.json
reset = False


[dataset_list_item_label_test_valid]
class = FilterDataset
input = list_item_label_test
filters = ("要素类别标注" in x) and ( x["要素类别标注"] in ['专业','分部分项','材料','材料属性','构件','构件属性','工序','工种','费用','机械','群体','单体','配套建筑','楼层','流水段','空间','地上地下','部位构件'])


[dataset_list_item_label_test_trans]
class = MapDataset
input = list_item_label_test_valid
expression = exec('import uuid') or {'item_id': uuid.uuid4().hex, 'label': x["要素类别标注"], "text": x["labeled_text"], "context": x["原始文本"] if x["工程名称-上级信息-项目名称"] is None else "-".join([x["工程名称-上级信息-项目名称"], x["原始文本"]])}
keep_exists = True
reset = True


[dataset_list_item_label_test_test]
class = FilterDataset
input = list_item_label_test_trans
filters = ("item_id" in x) and ( int(x["item_id"][-5:],16) % 10 < 5 )


[dataset_list_item_label_test_train]
class = FilterDataset
input = list_item_label_test_trans
filters = ("item_id" in x) and ( int(x["item_id"][-5:],16) % 10 >= 5 )



[evaluator_expert_predictor]
class = SimplePredictor
; datasets = list_item_label_test_trans
datasets = list_item_label_test_test
models = pretrained_trained.low_lr,pretrained_trained,base_trained


[evaluator_expert_evaluator]
class=MultiClassificationEvaluator
categories = 专业,分部分项,材料,材料属性,构件,构件属性,工序,工种,费用,机械,群体,单体,配套建筑,楼层,流水段,空间,地上地下,部位构件
; dataset= list_item_label_test_trans
dataset = list_item_label_test_test
models = pretrained_trained.low_lr,pretrained_trained,base_trained

############################################


[dataset_topk]
class = model_runner.datasets.sorted_dataset.TopKDataset
input = unlabeled
k = 1500
; sort_key = measure_entropy_score
; scp -r -P 61234 shilei@10.0.79.103:~/fbpmx/list_items_classification/list_items_classification_20231012/dataset_topk ./dataset_topk_`date "+%Y%m%d"`