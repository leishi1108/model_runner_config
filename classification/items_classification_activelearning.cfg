[DEFAULT]
workspace = /home/shilei/fbpmx/list_items_classification/list_items_classification_${date}
reset = True
re_predict = True


[project]
actions = generate

[datasets]
keys = list_item_label_train, train_candidate_word_position_feature, unlabeled, labeled, topk


[dataset_list_item_label_train]
class = ExistsDataset
reset = False
; copy from "/home/shilei/fbpmx/items_classification/items_classification_20231009/dataset_list_item_label_train"


[dataset_train_candidate_word_position_feature]
class = ReadFileDataset
format = json
dir = /home/shilei/corpus/list_items_data/list_item_label_train.json
reset = False

[dataset_train_candidate]
class = MapDataset
input = list_item_label_train
expression = exec('import uuid') or {'item_id': uuid.uuid4().hex}
keep_exists = True
reset = False


; [dataset_train_candidate_position_merge]
; class = MergeIntoDataset
; base_dataset = train_candidate
; merge_datasets = train_candidate_word_position_feature
; merge_type = merge_replace
; merge_key = item_id
; merge_values = classify_prediction,standard_prediction
; reset = False


[dataset_list_item_labeled]
class = ReadFileDataset
format = json
dir = /home/shilei/corpus/list_items_data/list_item_label_train_retrieve.json


[dataset_input]
class = MergeIntoDataset
base_dataset = train_candidate
merge_datasets = list_item_labeled
merge_type = merge_replace
merge_key = item_id
merge_values = classify_prediction,standard_prediction


; [dataset_input]
; class = FilterDataset
; input = train_candidate
; filters = True


[dataset_unlabeled]
class = FilterDataset
input = input
filters = ("classify_prediction" not in x) or (("classify_prediction" in x) and (x["classify_prediction"] is None))


[dataset_labeled]
class = FilterDataset
input = input
filters = ("classify_prediction" in x) and (x["classify_prediction"] is not None)



[model_items_classify]
class = MultiClassificationModel
data = labeled
bert_base = /home/shilei/model_repository/chinese-roberta-wwm-ext_ft
text=text
learning_rate = 2.0e-5
num_epochs = 50
train_ratio = 0.85
batch_size = 128
max_seq_length = 128
labels=专业,分部分项,材料,材料属性,构件,构件属性,工序,工种,费用,机械,群体,单体,配套建筑,楼层,流水段,空间


[dataset_topk]
class = model_runner.datasets.sorted_dataset.TopKDataset
input = unlabeled
k = 1500
sort_key = measure_entropy_score
; scp -r -P 61234 shilei@10.0.79.103:~/fbpmx/list_items_classification/list_items_classification_20231012/dataset_topk ./dataset_topk_`date "+%Y%m%d"`