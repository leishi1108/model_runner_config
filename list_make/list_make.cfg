[DEFAULT]
workspace = /home/shilei/fbpmx/list_make/list_make_${date}

[project]
actions = generate, evaluate, run
datasets = dwg_data, instrument_overall_grouped, instrument_overall_text_union, instrument_overall_text_split, instrument_overall_text_for_prediction, partial, num1_building_grouped, num1_building_grouped_trans, num1_building_text_paragraph, num1_building_partial_flattened, construction_grouped_trans
evaluators = instrument_overall_text_rebuild, instrument_overall_text_split_predict, num1_building_text_rebuild, num1_building_text_split_predict, num1_building_partial_match, construction_partial_match, num1_building_list_make_predict
stages = instrument_overall_export, instrument_overall_text_union_export, instrument_overall_text_split_export, instrument_overall_text_prediction_export, partial_export, num1_building_text_prediction_export, num1_building_partial_match_export, construction_partial_match_export

[dataset_raw_dwg_data]
class = DwgDataset
remote_url = http://10.127.91.94:9002
cluster_eps = 500
cluster_min_samples = 5
max_cluster_num = 20
dir = /home/shilei/corpus/list_make/重庆中海房建项目图纸-建筑和结构

[dataset_raw_dwg_data_test]
class = DwgDataset
remote_url = http://10.127.91.94:9001
dir = /home/shilei/corpus/list_make/重庆中海房建项目图纸-建筑和结构/19.10.26 中海项目结构最终版图纸（8.31）/中海项目结构最终版图纸（8.31）/车库OK

[dataset_raw_dwg_text_1]
class = FilterDataset
input = raw_dwg_data
filters = x["filename"] == "二十五~二十六层平面X向梁平法施工图.svg" and  x["filepath"] == "/home/shilei/corpus/list_make/重庆中海房建项目图纸-建筑和结构/19.10.26 中海项目结构最终版图纸（8.31）/中海项目结构最终版图纸（8.31）/1号楼OK/1号楼OK/1号楼图纸/1#楼标准层梁板_t3.dwg"

[dataset_raw_dwg_text_1_trans]
class = MapDataset
input = raw_dwg_text_1
expression = {"x": x["attrib"]["x"], "y": x["attrib"]["y"], "text": x["text"]}


[dataset_dwg_data]
class = MapDataset
input = raw_dwg_data
expression = exec('import re; import uuid; import json') or {
    "item_id": uuid.uuid3(uuid.NAMESPACE_DNS, str(x["filepath"]).split(".dwg")[0] + "-" + str(x["filename"]).split(".svg")[0] + "-" + str(x["attrib"]["id"]) ).hex,
    "item_key": str(x["filepath"]).split(".dwg")[0] + "-" + str(x["filename"]).split(".svg")[0] + "-" + str(x["attrib"]["id"]),
    "id": x["attrib"]["id"], "x": x["attrib"]["x"], "y": x["attrib"]["y"], "text": x["text"],
    "request": json.dumps( {"id": x["attrib"]["id"], "x": x["attrib"]["x"], "y": x["attrib"]["y"], "text": x["text"]}, ensure_ascii=False),
    }
keep_exists = True


################################### 结构设计总说明 ############################################################
[dataset_instrument_overall]
class = FilterDataset
input = dwg_data
filters = "结构设计总说明" in x["filename"] and "t3" not in x["filepath"].lower()

[stage_instrument_overall_export]
class = DatasetExportStage
dataset = instrument_overall
output_fields = item_id, item_key, dbscan_label, id, x, y, text, filename, filepath
output_names = item_id, item_key, dbscan_label, id, x, y, text, filename, filepath
save_res_path = /home/shilei/fbpmx/list_make/list_make_${date}/instrument_overall_export.xlsx


[dataset_instrument_overall_grouped]
class = GroupedDataset
input = instrument_overall
groupby = filepath, filename, dbscan_label
value_key = request


[evaluator_instrument_overall_text_rebuild]
class = SimplePredictor
datasets = instrument_overall_grouped
models = remote_text_rebuild_model
num_workers = 1

[model_remote_text_rebuild_model]
class = TextRebuildModel
url = http://10.0.79.55:9002
input_text_key = request
need_fields = request


[dataset_instrument_overall_text_union]
class = MapDataset
input = instrument_overall_grouped
expression = exec('import re; import uuid') or {
        "text": " ".join([m["text"] for m in x["remote_text_rebuild_model_score"]["json_output"]["ai_message"]]),
        "filepath": x["filepath"],
        "filename": x["filename"],
        "dbscan_label": x["dbscan_label"]
;         "request": x["request"]
    }
extra_dependencies = evaluator_instrument_overall_text_rebuild
keep_exists = False


[stage_instrument_overall_text_union_export]
class = DatasetExportStage
dataset = instrument_overall_text_union
output_fields = text, filename, filepath, dbscan_label
output_names = text, filename, filepath, dbscan_label
save_res_path = /home/shilei/fbpmx/list_make/list_make_${date}/instrument_overall_text_union_export.xlsx


[dataset_instrument_overall_text_split]
class = LiteralDataset
input = instrument_overall_text_union
text_key = text

[dataset_instrument_overall_text_for_prediction]
class = MapDataset
input = instrument_overall_text_split
expression = exec('import re; import uuid') or {
        "item_name": x["text"],
        "item_feature": "",
        "upper_item_name": "",
    }
keep_exists = True

[evaluator_instrument_overall_text_split_predict]
class = SimplePredictor
datasets = instrument_overall_text_for_prediction
models = gde_pricelib
num_workers = 1


[dataset_instrument_overall_text_prediction_for_export]
class = MapDataset
input = instrument_overall_text_for_prediction
expression = exec('import re; import uuid') or {
    "专业": ",".join(sorted(x["gde_pricelib_score"]["specialty_new"])) if x["gde_pricelib_score"] is not None else "",
    "分部分项": ",".join(sorted(x["gde_pricelib_score"]["cost-partial"])) if x["gde_pricelib_score"] is not None else "",
    "构件": ",".join(sorted(x["gde_pricelib_score"]["element"])) if x["gde_pricelib_score"] is not None else "",
    "材料": ",".join(sorted(x["gde_pricelib_score"]["material"])) if x["gde_pricelib_score"] is not None else "",
    }
keep_exists = True
extra_dependencies = evaluator_instrument_overall_text_split_predict

[stage_instrument_overall_text_prediction_export]
class = DatasetExportStage
dataset = instrument_overall_text_prediction_for_export
output_fields = text, filename, filepath, dbscan_label, 专业, 分部分项, 构件, 材料
output_names = text, filename, filepath, dbscan_label, 专业, 分部分项, 构件, 材料
save_res_path = /home/shilei/fbpmx/list_make/list_make_${date}/instrument_overall_text_prediction_export.xlsx


################ 1号楼 ########################

[dataset_num1_building]
class = FilterDataset
input = dwg_data
filters = ("1号楼" in x["filepath"] or "1#楼" in x["filepath"] ) and "t3" not in x["filepath"].lower()


[dataset_num1_building_grouped]
class = GroupedDataset
input = num1_building
groupby = filepath, filename, dbscan_label
value_key = request


[evaluator_num1_building_text_rebuild]
class = SimplePredictor
datasets = num1_building_grouped
models = remote_text_rebuild_model
num_workers = 1


[dataset_num1_building_grouped_trans]
class = MapDataset
input = num1_building_grouped
expression = exec('import re; import uuid') or {
        "file_key": str(x["filepath"]).split(".dwg")[0] + "-" + str(x["filename"]).split(".svg")[0] + "-" + str(x["dbscan_label"]),
        "request": x["request"],
        "text": x["remote_text_rebuild_model_score"]["json_output"]["ai_message"],
        "filepath": x["filepath"],
        "filename": x["filename"],
        "dbscan_label": x["dbscan_label"]
    }
extra_dependencies = evaluator_num1_building_text_rebuild
keep_exists = False

[dataset_num1_building_text_split]
class = LiteralDataset
input = num1_building_grouped_trans
text_key = text

[dataset_num1_building_text_for_prediction]
class = MapDataset
input = num1_building_text_split
expression = exec('import re; import uuid') or {
        "item_name": x["text"],
        "item_feature": "",
        "upper_item_name": "",
    }
keep_exists = True

[evaluator_num1_building_text_split_predict]
class = SimplePredictor
datasets = num1_building_text_for_prediction
models = gde_pricelib
num_workers = 1


[dataset_num1_building_text_prediction_for_export]
class = MapDataset
input = num1_building_text_for_prediction
expression = exec('import re; import uuid') or {
    "file_key": str(x["filepath"]).split(".dwg")[0] + "-" + str(x["filename"]).split(".svg")[0] + "-" + str(x["dbscan_label"]),
    "专业": ",".join(sorted(x["gde_pricelib_score"]["specialty_new"])) if x["gde_pricelib_score"] is not None else "",
    "分部分项": ",".join(sorted(x["gde_pricelib_score"]["cost-partial"])) if x["gde_pricelib_score"] is not None else "",
    "构件": ",".join(sorted(x["gde_pricelib_score"]["element"])) if x["gde_pricelib_score"] is not None else "",
    "材料": ",".join(sorted(x["gde_pricelib_score"]["material"])) if x["gde_pricelib_score"] is not None else "",
    }
keep_exists = True
extra_dependencies = evaluator_num1_building_text_split_predict


[stage_num1_building_text_prediction_export]
class = DatasetExportStage
dataset = num1_building_text_prediction_for_export
output_fields = text, filename, filepath, dbscan_label, 专业, 分部分项, 构件, 材料
output_names = text, filename, filepath, dbscan_label, 专业, 分部分项, 构件, 材料
save_res_path = /home/shilei/fbpmx/list_make/list_make_${date}/num1_building_text_prediction_export.xlsx



##################################################

[dataset_num1_building_text_paragraph]
class = LiteralDataset
input = num1_building_grouped_trans
text_key = text
sep = \n\n

[model_remote_text_partial_match]
class = PartialMatchModel
url = http://10.0.79.55:9002
input_text_key = text


[evaluator_num1_building_partial_match]
class = SimplePredictor
datasets = num1_building_text_paragraph
models = remote_text_partial_match
num_workers = 1

[dataset_num1_building_partial_match_for_export]
class = MapDataset
input = num1_building_text_paragraph
expression = exec('import re; import uuid') or {
    "file_key": str(x["filepath"]).split(".dwg")[0] + "-" + str(x["filename"]).split(".svg")[0] + "-" + str(x["dbscan_label"]),
    "匹配项目": x["remote_text_partial_match_score"]["json_output"]["ai_message"] if "ai_message" in x["remote_text_partial_match_score"]["json_output"] else "",
    }
keep_exists = True
extra_dependencies = evaluator_num1_building_partial_match

[stage_num1_building_partial_match_export]
class = DatasetExportStage
dataset = num1_building_partial_match_for_export
output_fields = text, filename, filepath, dbscan_label, 匹配项目
output_names = text, filename, filepath, dbscan_label, 匹配项目
save_res_path = /home/shilei/fbpmx/list_make/list_make_${date}/num1_building_partial_match_export.xlsx

######################### 清单生成 ################################

[dataset_raw_num1_building_partial_flattened]
class = FlatMapDataset
input = num1_building_text_paragraph
expression = list(map(lambda x: {"matched_partial": f"{x['分项']}_{x['项目名称']}"}, [m for m in eval(x["remote_text_partial_match_score"]["json_output"]["ai_message"]) if "分项" in m and "项目名称" in m]))
keep_exists = True
extra_dependencies = evaluator_num1_building_partial_match

[dataset_num1_building_partial_flattened]
class = FilterDataset
input = raw_num1_building_partial_flattened
filters = "matched_partial" in x and len(str(x["matched_partial"]).strip()) > 0


[model_remote_text_list_make]
class = ListMakeModel
url = http://10.0.79.55:9002
text_key = text
context_key = matched_partial
need_fields = text, matched_partial
re_predict = True

[evaluator_num1_building_list_make_predict]
class = SimplePredictor
datasets = num1_building_partial_flattened
models = remote_text_list_make
num_workers = 1

###########################################################################

[dataset_num1_building_text_paragraph_sentence]
class = LiteralDataset
input = num1_building_text_paragraph
text_key = text
new_key = sentence_text
sep = \n

[dataset_num1_building_text_paragraph_sentence_valid]
class = FilterDataset
input = num1_building_text_paragraph_sentence
filters = "sentence_text" in x and len(str(x["sentence_text"]).strip())>0

[dataset_num1_building_text_paragraph_sentence_for_prediction]
class = MapDataset
input = num1_building_text_paragraph_sentence_valid
expression = exec('import re; import uuid') or {
        "item_name": x["sentence_text"],
        "item_feature": x["text"],
        "upper_item_name": "",
    }
keep_exists = True


[evaluator_num1_building_text_paragraph_sentence_predict]
class = SimplePredictor
datasets = num1_building_text_paragraph_sentence_for_prediction
models = gde_pricelib
num_workers = 1


[dataset_num1_building_text_paragraph_sentence_prediction_for_export]
class = MapDataset
input = num1_building_text_paragraph_sentence_for_prediction
expression = exec('import re; import uuid') or {
    "专业": ",".join(sorted(x["gde_pricelib_score"]["specialty_new"])) if x["gde_pricelib_score"] is not None else "",
    "分部分项": ",".join(sorted(x["gde_pricelib_score"]["cost-partial"])) if x["gde_pricelib_score"] is not None else "",
    "构件": ",".join(sorted(x["gde_pricelib_score"]["element"])) if x["gde_pricelib_score"] is not None else "",
    "材料": ",".join(sorted(x["gde_pricelib_score"]["material"])) if x["gde_pricelib_score"] is not None else "",
    }
keep_exists = True
extra_dependencies = evaluator_num1_building_text_paragraph_sentence_predict


[stage_num1_building_text_paragraph_sentence_prediction_export]
class = DatasetExportStage
dataset = num1_building_text_paragraph_sentence_prediction_for_export
output_fields = text, filename, filepath, dbscan_label, 专业, 分部分项, 构件, 材料
output_names = text, filename, filepath, dbscan_label, 专业, 分部分项, 构件, 材料
save_res_path = /home/shilei/fbpmx/list_make/list_make_${date}/num1_building_text_paragraph_sentence_prediction_export.xlsx


[dataset_num1_building_text_paragraph_partial_grouped]
class = GroupedDataset
input = num1_building_text_paragraph_sentence_prediction_for_export
groupby = file_key
value_key = 分部分项

[dataset_num1_building_text_paragraph_element_grouped]
class = GroupedDataset
input = num1_building_text_paragraph_sentence_prediction_for_export
groupby = file_key
value_key = 构件

[dataset_num1_building_text_paragraph_material_grouped]
class = GroupedDataset
input = num1_building_text_paragraph_sentence_prediction_for_export
groupby = file_key
value_key = 材料

[dataset_num1_building_text_paragraph_mergePartial]
class = MergeIntoDataset
base_dataset = num1_building_text_paragraph
merge_datasets = num1_building_text_paragraph_partial_grouped
merge_type = only_replace
merge_key = file_key
merge_values = 分部分项
reset = False

[dataset_num1_building_text_paragraph_mergeElement]
class = MergeIntoDataset
base_dataset = num1_building_text_paragraph_mergePartial
merge_datasets = num1_building_text_paragraph_element_grouped
merge_type = only_replace
merge_key = file_key
merge_values = 构件
reset = False

[dataset_num1_building_text_paragraph_mergeMaterial]
class = MergeIntoDataset
base_dataset = num1_building_text_paragraph_mergeElement
merge_datasets = num1_building_text_paragraph_material_grouped
merge_type = only_replace
merge_key = file_key
merge_values = 材料
reset = False

[stage_num1_building_text_paragraph_match_prediction_export]
class = DatasetExportStage
dataset = num1_building_text_paragraph_mergeMaterial
output_fields = text, filename, filepath, dbscan_label, 匹配项目, 分部分项, 构件, 材料
output_names = text, filename, filepath, dbscan_label, 匹配项目, 分部分项, 构件, 材料
save_res_path = /home/shilei/fbpmx/list_make/list_make_${date}/num1_building_text_paragraph_match_prediction_export.xlsx


################ 施工图设计总说明 ########################

[dataset_construction]
class = FilterDataset
input = dwg_data
filters = "施工图设计总说明" in x["filepath"] and "t3" not in x["filepath"].lower()


[dataset_construction_grouped]
class = GroupedDataset
input = construction
groupby = filepath, filename, dbscan_label
value_key = request


[evaluator_construction_text_rebuild]
class = SimplePredictor
datasets = construction_grouped
models = remote_text_rebuild_model
num_workers = 1


[dataset_construction_grouped_trans]
class = MapDataset
input = construction_grouped
expression = exec('import re; import uuid') or {
        "file_key": str(x["filepath"]).split(".dwg")[0] + "-" + str(x["filename"]).split(".svg")[0] + "-" + str(x["dbscan_label"]),
        "request": x["request"],
        "text": x["remote_text_rebuild_model_score"]["json_output"]["ai_message"],
        "filepath": x["filepath"],
        "filename": x["filename"],
        "dbscan_label": x["dbscan_label"]
    }
extra_dependencies = evaluator_construction_text_rebuild
keep_exists = False


[dataset_construction_text_paragraph]
class = LiteralDataset
input = construction_grouped_trans
text_key = text
sep = \n\n


[evaluator_construction_partial_match]
class = SimplePredictor
datasets = construction_text_paragraph
models = remote_text_partial_match
num_workers = 1

[dataset_construction_partial_match_for_export]
class = MapDataset
input = construction_text_paragraph
expression = exec('import re; import uuid') or {
    "file_key": str(x["filepath"]).split(".dwg")[0] + "-" + str(x["filename"]).split(".svg")[0] + "-" + str(x["dbscan_label"]),
    "匹配项目": x["remote_text_partial_match_score"]["json_output"]["ai_message"] if "ai_message" in x["remote_text_partial_match_score"]["json_output"] else "",
    }
keep_exists = True
extra_dependencies = evaluator_construction_partial_match

[stage_construction_partial_match_export]
class = DatasetExportStage
dataset = construction_partial_match_for_export
output_fields = text, filename, filepath, dbscan_label, 匹配项目
output_names = text, filename, filepath, dbscan_label, 匹配项目
save_res_path = /home/shilei/fbpmx/list_make/list_make_${date}/construction_partial_match_export.xlsx

########################################

[model_gde_pricelib]
class = GDEPriceLibServiceModel
task_type = 清单
item_name_key = item_name
item_feature_key = item_feature
upper_item_name_key = upper_item_name
need_fields = item_name, item_feature, upper_item_name


[model_tjqd2]
class = GDETJQD2ServiceModel
task_type = 清单
item_name_key = item_name
item_feature_key = item_feature
upper_item_name_key = upper_item_name
project_name_key = project_name
need_fields = item_name,item_feature,upper_item_name,project_name


[stage_instrument_overall_text_split_export]
class = DatasetExportStage
dataset = instrument_overall_text_split
output_fields = text, filename, filepath, dbscan_label
output_names = text, filename, filepath, dbscan_label
save_res_path = /home/shilei/fbpmx/list_make/list_make_${date}/instrument_overall_text_split_export.xlsx


[dataset_partial]
class = ReadFileDataset
format = json
dir = /home/shilei/corpus/list_make/分部分项文档.json
reset = False


[stage_partial_export]
class = DatasetExportStage
dataset = partial
output_fields = 分部, 分项, 项目编码, 项目名称, 项目特征, 单位, 工程量计算规则, 工作内容
output_names = 分部, 分项, 项目编码, 项目名称, 项目特征, 单位, 工程量计算规则, 工作内容
save_res_path = /home/shilei/fbpmx/list_make/list_make_${date}/partial_export.xlsx