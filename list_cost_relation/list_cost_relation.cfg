[DEFAULT]
workspace = /home/shilei/fbpmx/list_cost_relation/list_cost_relation_${date}


[project]
actions = evaluate

[evaluators]
keys = total_pointwise
; keys = list_quota_cost_pointwise


[models]
keys = merge_ft_from_standard, merge_ft_from_standard.2, merge_ft_from_standard.rdrop, merge_ft_from_standard.rdrop2


[datasets]
keys = train_dataset, test_dataset

###################### list_quota_cost ############################

[dataset_project_list_quota_cost_out]
class = ReadFileDataset
format = json
dir = /home/yujh/GDE/datasets/corpus/list_cost_relation/project_list_quota_cost_sample_onlyleaf_fixed.json
; dir = /home/shilei/corpus/list_cost_relation/project_list_quota_cost_sample_onlyleaf.json
; dir = /home/shilei/corpus/list_cost_relation/project_list_quota_cost_out.json
; dir = /home/shilei/corpus/list_cost_relation/project_list_quota_cost_out_onlyleaf.json
reset = False


[dataset_project_list_quota_cost_trans]
class = MapDataset
input = project_list_quota_cost_out
expression = {'label': str(int(x["label"])),
              'text': "-".join([x["list_name"],x["quota_name"]]) if x["list_feature"] is None else "-".join([x["list_name"],x["quota_name"], x["list_feature"][:32]]),
              'context': x["cost_name_with_upper"]}
keep_exists = True


# [dataset_list_quota_cost_test]
# class = FilterDataset
# input = project_list_quota_cost_trans
# filters = ("pid" in x) and (int(x["pid"][-8:],16) % 10 < 1)

# [dataset_list_quota_cost_train]
# class = FilterDataset
# input = project_list_quota_cost_trans
# filters = ("pid" in x) and (int(x["pid"][-8:],16) % 10 >= 1)


[dataset_list_quota_cost_positive]
class = FilterDataset
input = project_list_quota_cost_trans
filters = ("label" in x) and (x["label"] == '1')


[dataset_list_quota_cost_negative]
class = FilterDataset
input = project_list_quota_cost_trans
filters = ("label" in x) and (x["label"] == '0')


[dataset_list_quota_cost_valid]
class = MergeDataset
datasets = list_quota_cost_positive, list_quota_cost_negative

###################### add part ###############################

[dataset_list_part]
class = ReadFileDataset
format = json
dir = /home/yujh/GDE/datasets/corpus/list_cost_relation/list_part_sample.json
reset = False

[dataset_list_quota_part]
class = ReadFileDataset
format = json
dir = /home/yujh/GDE/datasets/corpus/list_cost_relation/list_quota_part_sample.json
reset = False

[dataset_list_part_trans]
class = MapDataset
input = list_part
expression = {'label': str(int(x["label"])),
              'text': x["list_name"] if x["list_feature"] is None else "-".join([x["list_name"], x["list_feature"][:32]]),
              'context': x["part_full_name"],
              "quota_key": x["item_id"]}
keep_exists = True

[dataset_list_quota_part_trans]
class = MapDataset
input = list_quota_part
expression = {'label': str(int(x["label"])),
              'text': "-".join([x["list_name"], x["quota_name"]]),
              'context': x["part_full_name"],
              "quota_key": x["item_id"]}
keep_exists = True


# [dataset_train_add_part]
# class = MergeDataset
# datasets = list_quota_cost_train_valid, list_part_trans, list_quota_part_trans


############################ HaiTao list cost data ############################

[dataset_HaiTao_list_subject]
class = ReadFileDataset
format = json
dir = /data/yujh/GDE/datasets/corpus/list_cost_relation/not_sample_from_60w_data/list_subject_data_not_sample_neg_ins_10w_new_uid_with_brief_label_bq_item_title.json
reset = False


################################################################
# [dataset_HaiTao_list_subject_test]
# class = FilterDataset
# input = HaiTao_list_subject
# filters = ("pid" in x) and (int(x["pid"][-8:],16) % 10 < 1)

# [dataset_HaiTao_list_subject_train]
# class = FilterDataset
# input = HaiTao_list_subject
# filters = ("pid" in x) and (int(x["pid"][-8:],16) % 10 >= 1)


# [dataset_HaiTao_list_subject_filter]
# class = FilterDataset
# input = HaiTao_list_subject
# filters = ("pid" in x) and (int(x["pid"][-8:],16) % 200 < 1)

################################################################


[dataset_HaiTao_list_subject_feature_trans]
class = MapDataset
input = HaiTao_list_subject
expression = {'label': str(int(x["label"])),
              'text': "-".join([x["bq_item_title_with_upper"] if x["bq_item_title_with_upper"] is not None else "",x["list_name"] if x["list_name"] is not None else "",x["list_feature"] if x["list_feature"] is not None else ""]),
              'context': x["cost_name_with_upper"]}

keep_exists = True


# [dataset_HaiTao_list_subject_feature_test_trans]
# class = MapDataset
# input = HaiTao_list_subject_test
# expression = {'label': str(int(x["label"])),
#               'text': "-".join([x["list_name"] if x["list_name"] is not None else "",x["list_feature"] if x["list_feature"] is not None else ""]),
#               'context': x["cost_name_with_upper"]}

# keep_exists = True



[dataset_total_data]
class = MergeDataset
datasets = list_quota_cost_valid, list_part_trans, list_quota_part_trans, HaiTao_list_subject_feature_trans


[dataset_train_dataset]
class = FilterDataset
input = total_data
filters = ("pid" in x) and (int(x["pid"][-8:],16) % 10 >= 1)

[dataset_test_dataset]
class = FilterDataset
input = total_data
filters = ("pid" in x) and (int(x["pid"][-8:],16) % 10 < 1)


[model_merge_ft_from_standard]
class = BinaryClassificationModel
data = train_dataset
bert_base = /home/yujh/GDE/ckpts/model_repository/chinese-roberta-wwm-ext_ft
text=text
with_context=1
context=context
# learning_rate = 2.0e-5
learning_rate = 7.0e-5
freeze_bert = 2
num_epochs = 70
train_ratio = 0.85
# batch_size = 128
batch_size = 1024
max_seq_length = 128
positive = 1
negative = 0

[model_merge_ft_from_standard.2]
class = BinaryClassificationModel
data = train_dataset
bert_base = /home/yujh/GDE/ckpts/model_repository/chinese-roberta-wwm-ext_ft
text=text
with_context=1
context=context
# learning_rate = 2.0e-5
learning_rate = 7.0e-5
freeze_bert = 2
num_epochs = 70
train_ratio = 0.85
# batch_size = 128
batch_size = 1024
max_seq_length = 128
positive = 1
negative = 0

[model_merge_ft_from_standard.rdrop]
class = BinaryClassificationModel
data = train_dataset
bert_base = /home/yujh/GDE/ckpts/model_repository/chinese-roberta-wwm-ext_ft
text=text
with_context=1
context=context
# learning_rate = 2.0e-5
learning_rate = 7.0e-5
freeze_bert = 2
num_epochs = 70
train_ratio = 0.85
# batch_size = 128
batch_size = 512
max_seq_length = 128
positive = 1
negative = 0
r_drop_alpha = 4.0

[model_merge_ft_from_standard.rdrop2]
class = BinaryClassificationModel
data = train_dataset
bert_base = /home/yujh/GDE/ckpts/model_repository/chinese-roberta-wwm-ext_ft
text=text
with_context=1
context=context
# learning_rate = 2.0e-5
# learning_rate = 5.0e-5
learning_rate = 7.0e-5
freeze_bert = 2
num_epochs = 70
train_ratio = 0.85
# batch_size = 128
# batch_size = 256
batch_size = 512
max_seq_length = 128
positive = 1
negative = 0
r_drop_alpha = 4.0



[evaluator_total_pointwise]
class=BinaryClassificationEvaluator
positive = 1
negative = 0
dataset = test_dataset
models = merge_ft_from_standard, merge_ft_from_standard.rdrop, merge_ft_from_standard.rdrop2, merge_ft_from_standard.2
threshold = 0.5
